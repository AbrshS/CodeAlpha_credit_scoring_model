{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit Scoring Model for Financial Distress Prediction\n",
    "# Predicting 90+ days delinquency using the \"Give Me Some Credit\" dataset\n",
    "\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, confusion_matrix, classification_report, roc_curve, auc, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset files already exist in Data directory\n",
      "Dataset shape: (150000, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.766127</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>0.802982</td>\n",
       "      <td>9120.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.957151</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.121876</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.658180</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0.085113</td>\n",
       "      <td>3042.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.233810</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036050</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.907239</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0.024926</td>\n",
       "      <td>63588.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines  age  \\\n",
       "1                 1                              0.766127   45   \n",
       "2                 0                              0.957151   40   \n",
       "3                 0                              0.658180   38   \n",
       "4                 0                              0.233810   30   \n",
       "5                 0                              0.907239   49   \n",
       "\n",
       "   NumberOfTime30-59DaysPastDueNotWorse  DebtRatio  MonthlyIncome  \\\n",
       "1                                     2   0.802982         9120.0   \n",
       "2                                     0   0.121876         2600.0   \n",
       "3                                     1   0.085113         3042.0   \n",
       "4                                     0   0.036050         3300.0   \n",
       "5                                     1   0.024926        63588.0   \n",
       "\n",
       "   NumberOfOpenCreditLinesAndLoans  NumberOfTimes90DaysLate  \\\n",
       "1                               13                        0   \n",
       "2                                4                        0   \n",
       "3                                2                        1   \n",
       "4                                5                        0   \n",
       "5                                7                        0   \n",
       "\n",
       "   NumberRealEstateLoansOrLines  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "1                             6                                     0   \n",
       "2                             0                                     0   \n",
       "3                             0                                     0   \n",
       "4                             0                                     0   \n",
       "5                             1                                     0   \n",
       "\n",
       "   NumberOfDependents  \n",
       "1                 2.0  \n",
       "2                 1.0  \n",
       "3                 0.0  \n",
       "4                 0.0  \n",
       "5                 0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "# Create Data directory if it doesn't exist\n",
    "if not os.path.exists('Data'):\n",
    "    os.makedirs('Data')\n",
    "\n",
    "# Check if data files already exist\n",
    "if not os.path.exists('Data/cs-training.csv'):\n",
    "    try:\n",
    "        # Try to download using Kaggle API\n",
    "        !kaggle competitions download -c GiveMeSomeCredit -p Data\n",
    "        !unzip Data/GiveMeSomeCredit.zip -d Data\n",
    "        print(\"Dataset downloaded successfully using Kaggle API\")\n",
    "    except:\n",
    "        print(\"Could not download using Kaggle API. Please download manually from https://www.kaggle.com/c/GiveMeSomeCredit/data\")\n",
    "        print(\"and place the files in the Data directory.\")\n",
    "else:\n",
    "    print(\"Dataset files already exist in Data directory\")\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Data/cs-training.csv', index_col=0)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed dataframe shape: (150000, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "      <th>WeightedDelinquency</th>\n",
       "      <th>IncomeToDependentsRatio</th>\n",
       "      <th>CreditLinesPerYear</th>\n",
       "      <th>HighUtilization</th>\n",
       "      <th>NoIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.766127</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>0.802982</td>\n",
       "      <td>9120.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3040.0</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.957151</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.121876</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.658180</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0.085113</td>\n",
       "      <td>3042.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3042.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.233810</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036050</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.907239</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0.024926</td>\n",
       "      <td>63588.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>63588.0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines  age  \\\n",
       "1                 1                              0.766127   45   \n",
       "2                 0                              0.957151   40   \n",
       "3                 0                              0.658180   38   \n",
       "4                 0                              0.233810   30   \n",
       "5                 0                              0.907239   49   \n",
       "\n",
       "   NumberOfTime30-59DaysPastDueNotWorse  DebtRatio  MonthlyIncome  \\\n",
       "1                                     2   0.802982         9120.0   \n",
       "2                                     0   0.121876         2600.0   \n",
       "3                                     1   0.085113         3042.0   \n",
       "4                                     0   0.036050         3300.0   \n",
       "5                                     1   0.024926        63588.0   \n",
       "\n",
       "   NumberOfOpenCreditLinesAndLoans  NumberOfTimes90DaysLate  \\\n",
       "1                               13                        0   \n",
       "2                                4                        0   \n",
       "3                                2                        1   \n",
       "4                                5                        0   \n",
       "5                                7                        0   \n",
       "\n",
       "   NumberRealEstateLoansOrLines  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "1                             6                                     0   \n",
       "2                             0                                     0   \n",
       "3                             0                                     0   \n",
       "4                             0                                     0   \n",
       "5                             1                                     0   \n",
       "\n",
       "   NumberOfDependents  WeightedDelinquency  IncomeToDependentsRatio  \\\n",
       "1                 2.0                  0.8                   3040.0   \n",
       "2                 1.0                  0.0                   1300.0   \n",
       "3                 0.0                  1.0                   3042.0   \n",
       "4                 0.0                  0.0                   3300.0   \n",
       "5                 0.0                  0.4                  63588.0   \n",
       "\n",
       "   CreditLinesPerYear  HighUtilization  NoIncome  \n",
       "1            0.481481                0         0  \n",
       "2            0.181818                1         0  \n",
       "3            0.100000                0         0  \n",
       "4            0.416667                0         0  \n",
       "5            0.225806                1         0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data preprocessing function\n",
    "def preprocess_data(df):\n",
    "    # Create a copy of the dataframe\n",
    "    processed_df = df.copy()\n",
    "    \n",
    "    # Handle missing values\n",
    "    # Impute MonthlyIncome with median by age groups\n",
    "    age_groups = pd.cut(processed_df['age'], bins=[0, 30, 40, 50, 60, 100])\n",
    "    for group in age_groups.unique():\n",
    "        group_median = processed_df.loc[age_groups == group, 'MonthlyIncome'].median()\n",
    "        processed_df.loc[(age_groups == group) & (processed_df['MonthlyIncome'].isnull()), 'MonthlyIncome'] = group_median\n",
    "    \n",
    "    # If there are still missing values, use overall median\n",
    "    if processed_df['MonthlyIncome'].isnull().sum() > 0:\n",
    "        overall_median = processed_df['MonthlyIncome'].median()\n",
    "        processed_df['MonthlyIncome'].fillna(overall_median, inplace=True)\n",
    "    \n",
    "    # Replace null NumberOfDependents with 0\n",
    "    processed_df['NumberOfDependents'].fillna(0, inplace=True)\n",
    "    \n",
    "    # Cap extreme values\n",
    "    # Cap age between 21 and 100\n",
    "    processed_df['age'] = np.clip(processed_df['age'], 21, 100)\n",
    "    \n",
    "    # Cap NumberOfTimes90DaysLate to 20\n",
    "    processed_df['NumberOfTimes90DaysLate'] = np.clip(processed_df['NumberOfTimes90DaysLate'], 0, 20)\n",
    "    \n",
    "    # Feature engineering\n",
    "    # Create WeightedDelinquency\n",
    "    processed_df['WeightedDelinquency'] = (0.4 * processed_df['NumberOfTime30-59DaysPastDueNotWorse'] + \n",
    "                                          0.6 * processed_df['NumberOfTimes90DaysLate'])\n",
    "    \n",
    "    # Create IncomeToDependentsRatio\n",
    "    processed_df['IncomeToDependentsRatio'] = processed_df['MonthlyIncome'] / (processed_df['NumberOfDependents'] + 1)\n",
    "    \n",
    "    # Create CreditLinesPerYear for those over 18\n",
    "    processed_df['CreditLinesPerYear'] = 0\n",
    "    mask = processed_df['age'] > 18\n",
    "    processed_df.loc[mask, 'CreditLinesPerYear'] = processed_df.loc[mask, 'NumberOfOpenCreditLinesAndLoans'] / (processed_df.loc[mask, 'age'] - 18)\n",
    "    \n",
    "    # Create risk flags\n",
    "    processed_df['HighUtilization'] = (processed_df['RevolvingUtilizationOfUnsecuredLines'] > 0.8).astype(int)\n",
    "    processed_df['NoIncome'] = (processed_df['MonthlyIncome'] <= 0).astype(int)\n",
    "    \n",
    "    return processed_df\n",
    "\n",
    "# Apply preprocessing\n",
    "processed_df = preprocess_data(df)\n",
    "\n",
    "# Display the processed dataframe\n",
    "print(\"Processed dataframe shape:\", processed_df.shape)\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression (Baseline Model)...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best parameters: {'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best cross-validation ROC-AUC: 0.8161\n",
      "\n",
      "Training Random Forest (Primary Model)...\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Best parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Best cross-validation ROC-AUC: 0.9899\n",
      "\n",
      "Training XGBoost (Comparison Model)...\n",
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "Best parameters: {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 300, 'subsample': 0.9}\n",
      "Best cross-validation ROC-AUC: 0.9854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/scaler.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare data for modeling\n",
    "def prepare_model_data(df):\n",
    "    # Define features and target\n",
    "    X = df.drop('SeriousDlqin2yrs', axis=1)\n",
    "    y = df['SeriousDlqin2yrs']\n",
    "    \n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, X_train_scaled, X_test_scaled, scaler\n",
    "\n",
    "# Prepare the data\n",
    "X_train, X_test, y_train, y_test, X_train_scaled, X_test_scaled, scaler = prepare_model_data(processed_df)\n",
    "\n",
    "# Function to train models with SMOTE during cross-validation\n",
    "def train_model_with_smote_cv(model, X_train, y_train, param_grid=None, cv=5):\n",
    "    # Define cross-validation strategy\n",
    "    cv_strategy = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    \n",
    "    # If param_grid is provided, perform grid search\n",
    "    if param_grid:\n",
    "        # Initialize GridSearchCV with ROC-AUC scoring\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grid,\n",
    "            scoring='roc_auc',\n",
    "            cv=cv_strategy,\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Apply SMOTE and fit the model\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "        grid_search.fit(X_resampled, y_resampled)\n",
    "        \n",
    "        # Get the best model\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "        best_score = grid_search.best_score_\n",
    "        \n",
    "        print(f\"Best parameters: {best_params}\")\n",
    "        print(f\"Best cross-validation ROC-AUC: {best_score:.4f}\")\n",
    "        \n",
    "        return best_model\n",
    "    else:\n",
    "        # If no param_grid, just perform cross-validation with SMOTE\n",
    "        cv_scores = []\n",
    "        \n",
    "        for train_idx, val_idx in cv_strategy.split(X_train, y_train):\n",
    "            # Split data\n",
    "            X_cv_train, X_cv_val = X_train[train_idx], X_train[val_idx]\n",
    "            y_cv_train, y_cv_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "            \n",
    "            # Apply SMOTE\n",
    "            smote = SMOTE(random_state=42)\n",
    "            X_resampled, y_resampled = smote.fit_resample(X_cv_train, y_cv_train)\n",
    "            \n",
    "            # Train model\n",
    "            model.fit(X_resampled, y_resampled)\n",
    "            \n",
    "            # Predict and calculate ROC-AUC\n",
    "            y_pred_proba = model.predict_proba(X_cv_val)[:, 1]\n",
    "            cv_score = roc_auc_score(y_cv_val, y_pred_proba)\n",
    "            cv_scores.append(cv_score)\n",
    "        \n",
    "        # Train final model on all training data with SMOTE\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "        model.fit(X_resampled, y_resampled)\n",
    "        \n",
    "        print(f\"Cross-validation ROC-AUC: {np.mean(cv_scores):.4f} (±{np.std(cv_scores):.4f})\")\n",
    "        \n",
    "        return model\n",
    "\n",
    "# Train Logistic Regression (baseline model)\n",
    "print(\"Training Logistic Regression (Baseline Model)...\")\n",
    "log_reg_params = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear']\n",
    "}\n",
    "log_reg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "best_log_reg = train_model_with_smote_cv(log_reg, X_train_scaled, y_train, log_reg_params)\n",
    "\n",
    "# Train Random Forest (primary model)\n",
    "print(\"\\nTraining Random Forest (Primary Model)...\")\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "best_rf = train_model_with_smote_cv(rf, X_train_scaled, y_train, rf_params)\n",
    "\n",
    "# Train XGBoost (comparison model)\n",
    "print(\"\\nTraining XGBoost (Comparison Model)...\")\n",
    "xgb_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "}\n",
    "xgb_model = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "best_xgb = train_model_with_smote_cv(xgb_model, X_train_scaled, y_train, xgb_params)\n",
    "\n",
    "# Save the models\n",
    "import joblib\n",
    "os.makedirs('models', exist_ok=True)\n",
    "joblib.dump(best_log_reg, 'models/logistic_regression.pkl')\n",
    "joblib.dump(best_rf, 'models/random_forest.pkl')\n",
    "joblib.dump(best_xgb, 'models/xgboost.pkl')\n",
    "joblib.dump(scaler, 'models/scaler.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
